# ü§ñ LLM Analysis - Quick Start

## Co Masz Teraz

‚úÖ **Gotowe prompty** do analizy `full_result.json` przez AI
‚úÖ **System prompt** - instrukcje dla modelu
‚úÖ **User prompt** - szablon zapytania
‚úÖ **Przyk≈Çady u≈ºycia** - Python, n8n, API
‚úÖ **Przyk≈Çadowa odpowied≈∫** - jak wyglƒÖda raport

---

## üìÅ Pliki

| Plik | Opis | U≈ºycie |
|------|------|--------|
| `LLM_PROMPT_FULL_RESULT.md` | Pe≈Çna dokumentacja prompt√≥w | Przeczytaj |
| `prompt_system.txt` | System prompt (gotowy) | Skopiuj |
| `prompt_user.txt` | User prompt (szablon) | Skopiuj + dostosuj |
| `EXAMPLE_LLM_USAGE.md` | Praktyczne przyk≈Çady | Implementuj |
| `LLM_QUICK_START.md` | Ten plik | Start |

---

## ‚ö° Szybki Start (2 minuty)

### Krok 1: Otw√≥rz Claude / ChatGPT / Gemini

### Krok 2: Skopiuj System Prompt

Otw√≥rz: `prompt_system.txt`
Skopiuj ca≈Ço≈õƒá
Wklej jako "System Prompt" lub "Instrukcja systemowa"

### Krok 3: Skopiuj User Prompt + JSON

Otw√≥rz: `prompt_user.txt`
Skopiuj ca≈Ço≈õƒá
Znajd≈∫ miejsce: `[WKLEJ TUTAJ ZAWARTO≈öƒÜ full_result.json]`
Wklej zawarto≈õƒá swojego pliku JSON
Dostosuj kontekst w linii: `Kontekst: [...]`

### Krok 4: Wy≈õlij i Otrzymaj Raport

AI wygeneruje szczeg√≥≈Çowy raport zawierajƒÖcy:
- Executive Summary
- Zmiany Krytyczne
- Zmiany Istotne
- Zmiany Mniejsze
- Dodane/Usuniƒôte Tre≈õci
- Rekomendacje

---

## üéØ U≈ºycie w n8n

### Workflow:

```
1. Get Full Result (HTTP Request)
    ‚Üì
2. Read System Prompt (Read File: prompt_system.txt)
    ‚Üì
3. AI Analysis (OpenAI/Anthropic Node)
    - System: {{ $('Read System Prompt').item.json }}
    - User: "Przeanalizuj: {{ JSON.stringify($('Get Full Result').item.json) }}"
    ‚Üì
4. Send Report (Email/Slack/Save)
```

### Konfiguracja Node'a AI:

**OpenAI Node:**
```
Model: gpt-4-turbo-preview
System Message: [zawarto≈õƒá prompt_system.txt]
User Message: [zawarto≈õƒá prompt_user.txt + JSON]
Max Tokens: 4000
```

**Anthropic (Claude) Node:**
```
Model: claude-3-5-sonnet-20241022
System: [zawarto≈õƒá prompt_system.txt]
Prompt: [zawarto≈õƒá prompt_user.txt + JSON]
Max Tokens: 4000
```

---

## üíª U≈ºycie w Python

### Prosty Skrypt:

```python
import json
import anthropic  # lub openai

# 1. Wczytaj pliki
with open('prompt_system.txt', 'r', encoding='utf-8') as f:
    system_prompt = f.read()

with open('prompt_user.txt', 'r', encoding='utf-8') as f:
    user_prompt = f.read()

with open('full_result.json', 'r', encoding='utf-8') as f:
    result_data = json.load(f)

# 2. Wstaw JSON do promptu
json_str = json.dumps(result_data, ensure_ascii=False, indent=2)
user_final = user_prompt.replace(
    '[WKLEJ TUTAJ ZAWARTO≈öƒÜ full_result.json]',
    json_str
)

# 3. Wywo≈Çaj AI
client = anthropic.Anthropic(api_key="your-key")
response = client.messages.create(
    model="claude-3-5-sonnet-20241022",
    max_tokens=4000,
    system=system_prompt,
    messages=[{"role": "user", "content": user_final}]
)

# 4. Wy≈õwietl/Zapisz raport
print(response.content[0].text)

# Opcjonalnie: zapisz do pliku
with open('ai_report.md', 'w', encoding='utf-8') as f:
    f.write(response.content[0].text)
```

---

## üîß Dostosowania

### Zmie≈Ñ Kontekst Domenowy:

W `prompt_user.txt` znajd≈∫ liniƒô:
```
Kontekst: [opisz domenƒô dokumentu]
```

Zmie≈Ñ na np.:
- `Kontekst: Polityka ZarzƒÖdzania Ryzykiem ICT - dokument bankowy, wymogi DORA`
- `Kontekst: Umowa SLA - dokument techniczny, parametry wydajno≈õci`
- `Kontekst: Regulamin Pracy - dokument HR, przepisy prawa pracy`

### Dodaj Specyficzne Pytania:

Na ko≈Ñcu User Prompt dodaj:
```
Dodatkowo odpowiedz na pytania:
1. Czy zmiany sƒÖ zgodne z RODO?
2. Czy wymaga to zgody ZarzƒÖdu?
3. Jaki jest szacowany czas implementacji?
```

### Zmie≈Ñ Format Raportu:

W User Prompt zmie≈Ñ sekcjƒô "FORMAT ODPOWIEDZI" na w≈Çasny, np.:
```
FORMAT ODPOWIEDZI:
1. Streszczenie (max 3 zdania)
2. Top 5 najwa≈ºniejszych zmian (bullet points)
3. Podsumowanie wp≈Çywu (high/medium/low)
4. Rekomendowane dzia≈Çania (checklist)
```

---

## üìä Przyk≈Çadowa Odpowied≈∫

Po wys≈Çaniu promptu otrzymasz raport podobny do:

```markdown
# RAPORT ANALIZY ZMIAN

## EXECUTIVE SUMMARY
Wykryto 12 zmian w dokumencie, w tym 3 krytyczne dotyczƒÖce
struktury organizacyjnej. Zmiany wymagajƒÖ zatwierdzenia ZarzƒÖdu
i aktualizacji procedur.

## ZMIANY KRYTYCZNE

### 1. Zmiana W≈Ça≈õciciela Polityki (Paragraf #11)
- Stare: Chief Risk Officer (CRO)
- Nowe: Chief Operating Officer (COO)
- Wp≈Çyw: Zmiana odpowiedzialno≈õci wymaga aktualizacji RACI

[... dalsze szczeg√≥≈Çy ...]

## REKOMENDACJE
1. Aktualizacja matrycy odpowiedzialno≈õci ‚ö†Ô∏è
2. Komunikacja zmian do stakeholder√≥w üì¢
3. Weryfikacja zgodno≈õci z DORA ‚úì
```

---

## üéì Best Practices

### ‚úÖ DO:
- Dodawaj kontekst domenowy
- Okre≈õl cel analizy (compliance/technical/business)
- Wskazuj na co zwr√≥ciƒá szczeg√≥lnƒÖ uwagƒô
- Pro≈õ o konkretny format odpowiedzi
- Testuj na ma≈Çych plikach najpierw

### ‚ùå DON'T:
- Nie wysy≈Çaj wra≈ºliwych danych do publicznych API
- Nie u≈ºywaj zbyt du≈ºych plik√≥w (>100KB) bez filtrowania
- Nie ignoruj kontekstu biznesowego
- Nie polegaj tylko na AI - weryfikuj wyniki
- Nie u≈ºywaj starych modeli (GPT-3.5, Claude-2)

---

## üí∞ Szacunkowe Koszty

### Przyk≈Çadowy plik (20KB JSON):

| Model | Tokeny Input | Tokeny Output | Koszt |
|-------|--------------|---------------|-------|
| GPT-4 Turbo | ~8000 | ~2000 | ~$0.12 |
| Claude Sonnet | ~8000 | ~2000 | ~$0.06 |
| Gemini Pro | ~8000 | ~2000 | ~$0.00 (darmowe do limitu) |

**Wskaz√≥wka:** Dla ma≈Çych dokument√≥w (<50 paragraf√≥w) koszty sƒÖ minimalne.

---

## üîê Bezpiecze≈Ñstwo

### Dane Publiczne:
‚úÖ Mo≈ºesz u≈ºywaƒá Claude.ai, ChatGPT, Gemini

### Dane Wra≈ºliwe:
‚ö†Ô∏è U≈ºyj:
- Azure OpenAI (danych nie u≈ºywa do treningu)
- AWS Bedrock (w≈Çasna infrastruktura)
- Lokalny model (Llama, Mistral via Ollama)

### Anonimizacja:
```python
def anonymize_json(data):
    """Zamie≈Ñ wra≈ºliwe dane na placeholdery"""
    # Zamie≈Ñ nazwiska, numery, adresy itp.
    text = json.dumps(data)
    text = re.sub(r'\b[A-Z][a-z]+ [A-Z][a-z]+\b', '[NAZWA]', text)
    text = re.sub(r'\b\d{3}-\d{3}-\d{3}\b', '[NUMER]', text)
    return json.loads(text)
```

---

## üìö Dalsze Materia≈Çy

- **Pe≈Çna dokumentacja:** `LLM_PROMPT_FULL_RESULT.md`
- **Przyk≈Çady kodu:** `EXAMPLE_LLM_USAGE.md`
- **API dokumentacja:** `README.md`
- **n8n integration:** `N8N_GUIDE.md`

---

## üÜò Troubleshooting

### Problem: Token limit exceeded

**RozwiƒÖzanie:**
- Filtruj tylko `type="modified"` przed wys≈Çaniem
- U≈ºyj modelu z wiƒôkszym limitem (GPT-4-32k, Claude-3-200k)
- Podziel dokument na czƒô≈õci

### Problem: Niska jako≈õƒá analizy

**RozwiƒÖzanie:**
- Dodaj wiƒôcej kontekstu domenowego
- U≈ºyj przyk≈Çad√≥w (few-shot learning)
- Zmie≈Ñ model na lepszy (GPT-4 zamiast 3.5)

### Problem: Zbyt og√≥lne odpowiedzi

**RozwiƒÖzanie:**
- Zadaj konkretne pytania w prompcie
- Podaj template formatu odpowiedzi
- Popro≈õ o przyk≈Çady dla ka≈ºdej kategorii

---

## ‚úÖ Checklist

Przed u≈ºyciem upewnij siƒô:
- [ ] Masz plik `full_result.json`
- [ ] Skopiowa≈Çe≈õ `prompt_system.txt`
- [ ] Skopiowa≈Çe≈õ `prompt_user.txt`
- [ ] Wklei≈Çe≈õ JSON do user prompt
- [ ] Dostosowa≈Çe≈õ kontekst domenowy
- [ ] Wybra≈Çe≈õ platformƒô AI (Claude/ChatGPT/Gemini)
- [ ] Masz klucz API (je≈õli u≈ºywasz API)

---

## üéâ Gotowe!

Masz wszystko co potrzebne do analizy wynik√≥w przez AI.

**Nastƒôpny krok:**
1. Otw√≥rz `prompt_system.txt` i `prompt_user.txt`
2. Skopiuj do swojego AI
3. Wklej JSON
4. Otrzymaj raport!

---

*Quick Start Guide v1.0*
*Dzia≈Ça z: Claude, GPT-4, Gemini, Llama*
